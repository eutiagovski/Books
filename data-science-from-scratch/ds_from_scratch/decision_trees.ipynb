{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvores de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "def entropy(class_probabilities: List[float]) -> float:\n",
    "    \"\"\"Caso haja uma lista de probabilidades de classe, calcule a entropia\"\"\"\n",
    "    return sum(-p * math.log(p, 2)\n",
    "               for p in class_probabilities \n",
    "               if p > 0)                            # ignore probabilidades zero\n",
    "\n",
    "assert entropy([1.0]) == 0\n",
    "assert entropy([0.5, 0.5]) == 1\n",
    "assert 0.81 < entropy([0.25, 0.75]) < 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from collections import Counter\n",
    "\n",
    "# computando o valor da probabilidade das classes\n",
    "def class_probabilities(labels: List[Any]) -> List[float]:\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labels: List[Any]) -> float:\n",
    "    return entropy(class_probabilities(labels))\n",
    "\n",
    "assert data_entropy(['a']) == 0\n",
    "assert data_entropy([True, False]) == 1\n",
    "assert data_entropy([3, 4, 4, 4]) == entropy([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropia de uma partição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy(subsets: List[List[Any]]) -> float:\n",
    "    \"\"\"Retorna a entropia dessa partição dos dados em subconjuntos\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    \n",
    "    return sum(data_entropy(subset) * len(subset) / total_count\n",
    "               for subset in subsets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Optional\n",
    "\n",
    "class Candidate(NamedTuple):\n",
    "    level: str\n",
    "    lang: str\n",
    "    tweets: bool\n",
    "    phd: bool\n",
    "    did_well: Optional[bool] = None\n",
    "\n",
    "                  #  level     lang     tweets  phd  did_well\n",
    "inputs = [Candidate('Senior', 'Java',   False, False, False),\n",
    "          Candidate('Senior', 'Java',   False, True,  False),\n",
    "          Candidate('Mid',    'Python', False, False, True),\n",
    "          Candidate('Junior', 'Python', False, False, True),\n",
    "          Candidate('Junior', 'R',      True,  False, True),\n",
    "          Candidate('Junior', 'R',      True,  True,  False),\n",
    "          Candidate('Mid',    'R',      True,  True,  True),\n",
    "          Candidate('Senior', 'Python', False, False, False),\n",
    "          Candidate('Senior', 'R',      True,  False, True),\n",
    "          Candidate('Junior', 'Python', True,  False, True),\n",
    "          Candidate('Senior', 'Python', True,  True,  True),\n",
    "          Candidate('Mid',    'Python', False, True,  True),\n",
    "          Candidate('Mid',    'Java',   True,  False, True),\n",
    "          Candidate('Junior', 'Python', False, True,  False)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.6935361388961919\n",
      "lang 0.8601317128547441\n",
      "tweets 0.7884504573082896\n",
      "phd 0.8921589282623617\n"
     ]
    }
   ],
   "source": [
    "# Escrevendo uma função de particionamento\n",
    "\n",
    "from typing import Dict, TypeVar\n",
    "from collections import defaultdict\n",
    "\n",
    "T = TypeVar('T')            # tipo genérico para as entradas\n",
    "\n",
    "def partition_by(inputs: List[T], attribute: str) -> Dict[Any, List[T]]:\n",
    "    \"\"\"Particione as entradas em listas com base no atributo especificado\"\"\"\n",
    "    partitions: Dict[Any, List[T]] = defaultdict(list)\n",
    "    \n",
    "    for input in inputs:\n",
    "        key = getattr(input, attribute)     # valor do atributo especificado\n",
    "        partitions[key].append(input)       # adicione a entrada à partição correta\n",
    "    return partitions\n",
    "\n",
    "# função para computar a entropia\n",
    "def partition_entropy_by(inputs: List[Any],\n",
    "                         attribute: str,\n",
    "                         label_attribute: str) -> float:\n",
    "    \"\"\"Compute a entropia correspondente à partição especificada\"\"\"\n",
    "    # as partições contém as entradas\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "\n",
    "    # mas o partition_entropy só precisa dos rótulos das classes\n",
    "    labels = [[getattr(input, label_attribute) for input in partition]\n",
    "              for partition in partitions.values()]\n",
    "    \n",
    "    return partition_entropy(labels)\n",
    "\n",
    "# em seguida precisamos encontrar a partição com entropia mínima para o conjunto de dados inteiro\n",
    "for key in ['level', 'lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(inputs, key, 'did_well'))\n",
    "\n",
    "assert 0.69 < partition_entropy_by(inputs, 'level', 'did_well') < 0.70\n",
    "assert 0.86 < partition_entropy_by(inputs, 'lang', 'did_well') < 0.87\n",
    "assert 0.78 < partition_entropy_by(inputs, 'tweets', 'did_well') < 0.79\n",
    "assert 0.89 < partition_entropy_by(inputs, 'phd', 'did_well') < 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_inputs = [input for input in inputs if input.level == 'Senior']\n",
    "\n",
    "assert 0.4 == partition_entropy_by(senior_inputs, 'lang', 'did_well')\n",
    "assert 0.0 == partition_entropy_by(senior_inputs, 'tweets', 'did_well')\n",
    "assert 0.95 < partition_entropy_by(senior_inputs, 'phd', 'did_well') < 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Union, Any\n",
    "\n",
    "class Leaf(NamedTuple):\n",
    "    value: Any\n",
    "\n",
    "class Split(NamedTuple):\n",
    "    attribute: str\n",
    "    subtrees: dict\n",
    "    default_value: Any = None\n",
    "\n",
    "DecisionTree = Union[Leaf, Split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiring_tree = Split('level', {              # primeiro, considere \"level\"\n",
    "    'Junior': Split('phd', {                # se 'level' for 'Junior', analise 'phd'\n",
    "        False: Leaf(True),                  # se 'phd' for False, preveja True\n",
    "        True: Leaf(False)                   # se 'phd' for True, preveja False\n",
    "    }),\n",
    "    \"Mid\": Leaf(True),                      # se 'level' for \"Mid\", sempre preveja True\n",
    "    \"Senior\": Split('tweets', {             # se 'level' for 'Senior', analise 'tweets'\n",
    "        False: Leaf(False),                 # se 'tweets' for False, preveja False\n",
    "        True: Leaf(True)                    # se 'tweets' for True, preveja True\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree: DecisionTree, input: Any) -> Any:\n",
    "    \"\"\"Classifique a entrada usando a árvore de decisão indicada\"\"\"\n",
    "\n",
    "    # Se for um nó folha, retorne seu valor\n",
    "    if isinstance(tree, Leaf):\n",
    "        return tree.value\n",
    "    \n",
    "    # Caso contrário, a árvore consiste em um atributo de divisão\n",
    "    # e um dicionário cujas chaves são valores desse atributo\n",
    "    # e cujos valores são sub-árvores que serão consideradas em seguida\n",
    "    subtree_key = getattr(input, tree.attribute)\n",
    "\n",
    "    if subtree_key not in tree.subtrees:            # se não houver sub-árvore para a chave\n",
    "        return tree.default_value                   # retorna o valor padrão\n",
    "    \n",
    "    subtree = tree.subtrees[subtree_key]            # Escolha a sub-árvore adequada\n",
    "    return classify(subtree, input)                 # e use-a para classificar a entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representação da árvore a partir dos dados de treinamento\n",
    "\n",
    "def build_tree_id3(inputs: List[Any], split_attributes: List[str], target_attribute: str) -> DecisionTree:\n",
    "    # Conte os rótulos especificados\n",
    "    label_count = Counter(getattr(input, target_attribute) for input in inputs)\n",
    "\n",
    "    most_common_label = label_count.most_common(1)[0][0]\n",
    "\n",
    "    # Se houver só um rótulo, preveja esse rótulo\n",
    "    if len(label_count) == 1:\n",
    "        return Leaf(most_common_label)\n",
    "\n",
    "    # Se não restar nenhum atributo de divisão, retorne o rótulo majoritário\n",
    "    if not split_attributes:\n",
    "        return Leaf(most_common_label)\n",
    "\n",
    "    # Caso contrário, divida pelo melhor atributo\n",
    "    def split_entropy(attribute: str) -> float:\n",
    "        \"\"\"A função auxiliar para encontrar o melhor atributo\"\"\"\n",
    "        return partition_entropy_by(inputs, attribute, target_attribute)\n",
    "\n",
    "    best_attribute = min(split_attributes, key=split_entropy)\n",
    "\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_attributes = [a for a in split_attributes if a != best_attribute]\n",
    "\n",
    "    # Construa recursivamente as sub-árvores\n",
    "    subtrees = {attribute_value: build_tree_id3(subset, new_attributes, target_attribute) for attribute_value, subset in partitions.items()}\n",
    "\n",
    "    return Split(best_attribute, subtrees, default_value=most_common_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree_id3(inputs, ['level', 'lang', 'tweets', 'phd'], 'did_well')\n",
    "\n",
    "# Deve prever True\n",
    "assert classify(tree, Candidate(\"Junior\", \"Java\", True, False))\n",
    "\n",
    "# Deve prever False\n",
    "assert not classify(tree, Candidate(\"Junior\", \"Java\", True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# também é possível aplicá-la a valores inesperados\n",
    "\n",
    "assert classify(tree, Candidate(\"Intern\", \"Java\", True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
