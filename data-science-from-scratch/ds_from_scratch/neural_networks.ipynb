{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from linear_algebra.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from linear_algebra import Vector, dot\n",
    "\n",
    "def step_function(x: float) -> float:\n",
    "    return 1.0 if x >= 0 else 0\n",
    "\n",
    "def perceptron_output(weights: Vector, bias: float, x: Vector) -> float:\n",
    "    \"\"\"Retorna 1 se o perceptron 'disparar', 0 se não\"\"\"\n",
    "    calculation = dot(weights, x) + bias\n",
    "    return step_function(calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porta AND\n",
    "\n",
    "and_weights = [2., 2]\n",
    "and_bias = -3.\n",
    "\n",
    "assert perceptron_output(and_weights, and_bias, [1, 1]) == 1\n",
    "assert perceptron_output(and_weights, and_bias, [0, 1]) == 0\n",
    "assert perceptron_output(and_weights, and_bias, [1, 0]) == 0\n",
    "assert perceptron_output(and_weights, and_bias, [0, 0]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porta OR\n",
    "\n",
    "or_weights = [2., 2]\n",
    "or_bias = -1.\n",
    "\n",
    "assert perceptron_output(or_weights, or_bias, [1, 1]) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [0, 1]) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [1, 0]) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [0, 0]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porta NOT\n",
    "\n",
    "not_weights = [-2.]\n",
    "not_bias = 1.\n",
    "\n",
    "assert perceptron_output(not_weights, not_bias, [0]) == 1\n",
    "assert perceptron_output(not_weights, not_bias, [1]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porta XOR\n",
    "\n",
    "and_gate = min\n",
    "or_bias = max\n",
    "xor_gate = lambda x, y: 0 if x == y else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neurais Feed-Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função Sigmoid\n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid(t: float) -> float:\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "def neuron_output(weights: Vector, inputs: Vector) -> float:\n",
    "    # o weights inclui o termo de viés, as entradas incluem um 1\n",
    "    return sigmoid(dot(weights, inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def feed_forward(neural_network: List[List[Vector]], input_vector: Vector) -> List[Vector]:\n",
    "    \"\"\"\n",
    "    Alimenta o vetor de entrada na rede neural.\n",
    "    Retorna as saídas de todas as camadas (não só a última).\n",
    "    \"\"\"\n",
    "    outputs: List[Vector] = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]                # adicione uma constante\n",
    "        output = [neuron_output(neuron, input_with_bias)    # Compute a saída\n",
    "                  for neuron in layer]                      # para cada neurônio.\n",
    "        outputs.append(output)                              # Adicione os resultados.\n",
    "\n",
    "        # Agora a entrada da próxima camada é a saída da última\n",
    "        input_vector = output                               \n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "xor_network = [ # camada oculta\n",
    "                [[20., 20, -30],        # neurônio 'and'\n",
    "                [20., 20, -10]],        # neurônio 'or'\n",
    "                #  camada de saída\n",
    "                [[-60., 60, -30]]]      # neurônio de '2ª entrada, mas não a 1ª entrada'\n",
    "\n",
    "# o feed_forward retorna as saídas de todas as camadas para que [-1] receba a \n",
    "# saída final e para que [0] receba o valor do vetor resultante\n",
    "assert 0.000 < feed_forward(xor_network, [0, 0])[-1][0] < 0.001\n",
    "assert 0.999 < feed_forward(xor_network, [1, 0])[-1][0] < 1.000\n",
    "assert 0.999 < feed_forward(xor_network, [0, 1])[-1][0] < 1.000\n",
    "assert 0.000 < feed_forward(xor_network, [1, 1])[-1][0] < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retropropagação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para cálcular os gradientes\n",
    "\n",
    "def sqerror_gradients(network: List[List[Vector]],\n",
    "                      input_vector: Vector,\n",
    "                      target_vector: Vector) -> List[List[Vector]]:\n",
    "    \"\"\"\n",
    "    Quando houver uma rede neural, um vector de entrada e um vetor\n",
    "    de destino, faça uma previsão e compute o gradient descendente da perda\n",
    "    dos erros quadráticos com relação aos pesos dos neurônios.\n",
    "    \"\"\"\n",
    "    # passe pra frente\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # gradientes associados às saídas de pré-ativação dos neurônios de saída\n",
    "    output_deltas = [output * (1 - output) * (output - target) for output, target in zip(outputs, target_vector)]\n",
    "\n",
    "    # gradientes associados aos pesos dos neurônios de saída\n",
    "    output_grads = [[output_deltas[i] * hidden_output for hidden_output in hidden_outputs + [1]] for i, output_neuron in enumerate(network[-1])]\n",
    "\n",
    "    # gradientes associados às saídas de pré-ativação dos neurônios ocultos\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) * dot(output_deltas, [n[i] for n in network[-1]]) for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # gradientes associados aos pesos dos neurônios\n",
    "    hidden_grads = [[hidden_deltas[i] * input for input in input_vector + [1]] for i, hidden_neuron in enumerate(network[0])]\n",
    "\n",
    "    return [hidden_grads, output_grads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando a rede neural\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# dados de treinamento\n",
    "xs = [[0., 0], [0., 1], [1., 0], [1., 1]]\n",
    "ys = [[0.], [1.], [1.], [0.]]\n",
    "\n",
    "# comece com pesos aleatórios\n",
    "network = [\n",
    "    # camada oculta: 2 entradas -> 2 saídas\n",
    "    [[random.random() for _ in range(2 + 1)],           # 1° neurônio oculto\n",
    "    [random.random() for _ in range(2 + 1)]],           # 2° neurônio oculto\n",
    "    # camada de saída: 2 entradas -> 1 saída\n",
    "    [[random.random() for _ in range(2 + 1)]]           # 1° neurônio de saída\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neural net for xor: 100%|██████████| 20000/20000 [00:03<00:00, 6524.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from gradient_descent import gradient_step\n",
    "import tqdm\n",
    "\n",
    "def train():\n",
    "    learning_rate = 1.0\n",
    "\n",
    "    for epoch in tqdm.trange(20000, desc=\"neural net for xor\"):\n",
    "        for x, y in zip(xs, ys):\n",
    "            gradients = sqerror_gradients(network, x, y)\n",
    "\n",
    "            # dê um passo de gradiente para cada neurônio de cada camada\n",
    "            network = [\n",
    "                [gradient_step(neuron, grad, -learning_rate)\n",
    "                for neuron, grad in zip(layer, layer_grad)]\n",
    "                for layer, layer_grad in zip(network, gradients)\n",
    "            ]\n",
    "\n",
    "\n",
    "    # verifique se a rede aprendeu XOR\n",
    "    assert feed_forward(network, [0, 0])[-1][0] < 0.01\n",
    "    assert feed_forward(network, [0, 1])[-1][0] > 0.99\n",
    "    assert feed_forward(network, [1, 0])[-1][0] > 0.99\n",
    "    assert feed_forward(network, [1, 1])[-1][0] < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[6.953505610104289, 6.952785792366962, -3.1484761965046655],\n",
       "  [5.115899442661922, 5.115407875835949, -7.839603434415663]],\n",
       " [[10.961705832630562, -11.63060534664317, -5.144229056613082]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo: Fizz Buzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "fizz\n",
      "4\n",
      "buzz\n",
      "fizz\n",
      "7\n",
      "8\n",
      "fizz\n",
      "buzz\n",
      "11\n",
      "fizz\n",
      "13\n",
      "14\n",
      "fizz\n",
      "16\n",
      "17\n",
      "fizz\n",
      "19\n",
      "buzz\n",
      "fizz\n",
      "22\n",
      "23\n",
      "fizz\n",
      "buzz\n",
      "26\n",
      "fizz\n",
      "28\n",
      "29\n",
      "fizz\n",
      "31\n",
      "32\n",
      "fizz\n",
      "34\n",
      "buzz\n",
      "fizz\n",
      "37\n",
      "38\n",
      "fizz\n",
      "buzz\n",
      "41\n",
      "fizz\n",
      "43\n",
      "44\n",
      "fizz\n",
      "46\n",
      "47\n",
      "fizz\n",
      "49\n",
      "buzz\n",
      "fizz\n",
      "52\n",
      "53\n",
      "fizz\n",
      "buzz\n",
      "56\n",
      "fizz\n",
      "58\n",
      "59\n",
      "fizz\n",
      "61\n",
      "62\n",
      "fizz\n",
      "64\n",
      "buzz\n",
      "fizz\n",
      "67\n",
      "68\n",
      "fizz\n",
      "buzz\n",
      "71\n",
      "fizz\n",
      "73\n",
      "74\n",
      "fizz\n",
      "76\n",
      "77\n",
      "fizz\n",
      "79\n",
      "buzz\n",
      "fizz\n",
      "82\n",
      "83\n",
      "fizz\n",
      "buzz\n",
      "86\n",
      "fizz\n",
      "88\n",
      "89\n",
      "fizz\n",
      "91\n",
      "92\n",
      "fizz\n",
      "94\n",
      "buzz\n",
      "fizz\n",
      "97\n",
      "98\n",
      "fizz\n",
      "buzz\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1, 101):\n",
    "#     if i % 3 == 0: print('fizz')\n",
    "#     elif i % 5 == 0: print('buzz')\n",
    "#     elif i % 15 == 0: print('fizzbuzz')\n",
    "#     else: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizz_buzz_encode(x: int) -> Vector:\n",
    "    if x % 15 == 0: return [0, 0, 0, 1]\n",
    "    elif x % 5 == 0: return [0, 0, 1, 0]\n",
    "    elif x % 3 == 0: return [0, 1, 0, 0]\n",
    "    else: return [1, 0, 0, 0]\n",
    "\n",
    "assert fizz_buzz_encode(2) == [1, 0, 0, 0]\n",
    "assert fizz_buzz_encode(6) == [0, 1, 0, 0]\n",
    "assert fizz_buzz_encode(10) == [0, 0, 1, 0]\n",
    "assert fizz_buzz_encode(30) == [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(x: int) -> Vector:\n",
    "    binary: List[float] = []\n",
    "\n",
    "    for i in range(10):\n",
    "        binary.append(x % 2)\n",
    "        x = x // 2\n",
    "    \n",
    "    return binary\n",
    "\n",
    "assert binary_encode(0)         == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "assert binary_encode(1)         == [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "assert binary_encode(10)        == [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "assert binary_encode(101)       == [1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "assert binary_encode(999)       == [1, 1, 1, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [binary_encode(n) for n in range(101, 1024)]\n",
    "ys = [fizz_buzz_encode(n) for n in range(101, 1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 25\n",
    "\n",
    "network = [\n",
    "    # camada oculta: 10 entradas -> NUM_HIDDEN saídas\n",
    "    [[random.random() for _ in range(10 + 1)] for _ in range(NUM_HIDDEN)],\n",
    "    # camada de saída: NUM_HIDDEN entradas -> 4 saídas\n",
    "    [[random.random() for _ in range(NUM_HIDDEN + 1)] for _ in range(4)]\n",
    "]\n",
    "\n",
    "from linear_algebra import squared_distance\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "def train():\n",
    "    with tqdm.trange(500) as t:\n",
    "        for epoch in t:\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "            for x, y in zip(xs, ys):\n",
    "                predicted = feed_forward(network, x)[-1]\n",
    "                epoch_loss += squared_distance(predicted, y)\n",
    "                gradients = sqerror_gradients(network, x, y)\n",
    "\n",
    "                # Dê um passo de gradiente para cada neurônio de cada camada\n",
    "                network = [\n",
    "                    [gradient_step(neuron, grad, -learning_rate)\n",
    "                    for neuron, grad in zip(layer, layer_grad)]\n",
    "                    for layer, layer_grad in zip(network, gradients)\n",
    "                ]\n",
    "            \n",
    "            t.set_description(f\"fizz buzz (loss: {epoch_loss:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(xs: list) -> int:\n",
    "    \"\"\"Retorna o índice de maior valor\"\"\"\n",
    "    return max(range(len(xs)), key=lambda i: xs[i])\n",
    "\n",
    "assert argmax([0, -1]) == 0                     # itens[0] é o maior valor\n",
    "assert argmax([-1, 0]) == 1                     # itens[1] é o maior valor\n",
    "assert argmax([-1, 10, 5, 20, -3]) == 3         # itens[3] é o maior valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1\n",
      "2 2 2\n",
      "3 3 fizz\n",
      "4 fizzbuzz 4\n",
      "5 5 buzz\n",
      "6 fizzbuzz fizz\n",
      "7 7 7\n",
      "8 buzz 8\n",
      "9 buzz fizz\n",
      "10 10 buzz\n",
      "11 buzz 11\n",
      "12 fizzbuzz fizz\n",
      "13 13 13\n",
      "14 14 14\n",
      "15 15 fizzbuzz\n",
      "16 16 16\n",
      "17 17 17\n",
      "18 18 fizz\n",
      "19 19 19\n",
      "20 20 buzz\n",
      "21 21 fizz\n",
      "22 22 22\n",
      "23 23 23\n",
      "24 24 fizz\n",
      "25 25 buzz\n",
      "26 26 26\n",
      "27 27 fizz\n",
      "28 28 28\n",
      "29 29 29\n",
      "30 30 fizzbuzz\n",
      "31 31 31\n",
      "32 32 32\n",
      "33 33 fizz\n",
      "34 34 34\n",
      "35 35 buzz\n",
      "36 36 fizz\n",
      "37 37 37\n",
      "38 38 38\n",
      "39 39 fizz\n",
      "40 40 buzz\n",
      "41 41 41\n",
      "42 42 fizz\n",
      "43 43 43\n",
      "44 44 44\n",
      "45 45 fizzbuzz\n",
      "46 46 46\n",
      "47 47 47\n",
      "48 48 fizz\n",
      "49 49 49\n",
      "50 50 buzz\n",
      "51 51 fizz\n",
      "52 52 52\n",
      "53 53 53\n",
      "54 54 fizz\n",
      "55 55 buzz\n",
      "56 56 56\n",
      "57 57 fizz\n",
      "58 58 58\n",
      "59 59 59\n",
      "60 60 fizzbuzz\n",
      "61 61 61\n",
      "62 62 62\n",
      "63 63 fizz\n",
      "64 64 64\n",
      "65 65 buzz\n",
      "66 66 fizz\n",
      "67 67 67\n",
      "68 68 68\n",
      "69 69 fizz\n",
      "70 70 buzz\n",
      "71 71 71\n",
      "72 72 fizz\n",
      "73 73 73\n",
      "74 74 74\n",
      "75 75 fizzbuzz\n",
      "76 76 76\n",
      "77 77 77\n",
      "78 78 fizz\n",
      "79 79 79\n",
      "80 80 buzz\n",
      "81 81 fizz\n",
      "82 82 82\n",
      "83 83 83\n",
      "84 84 fizz\n",
      "85 85 buzz\n",
      "86 86 86\n",
      "87 87 fizz\n",
      "88 88 88\n",
      "89 89 89\n",
      "90 90 fizzbuzz\n",
      "91 91 91\n",
      "92 92 92\n",
      "93 93 fizz\n",
      "94 94 94\n",
      "95 95 buzz\n",
      "96 96 fizz\n",
      "97 97 97\n",
      "98 98 98\n",
      "99 99 fizz\n",
      "100 100 buzz\n",
      "50 / 100\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    num_correct = 0\n",
    "\n",
    "    for n in range(1, 101):\n",
    "        x = binary_encode(n)\n",
    "        predicted = argmax(feed_forward(network, x)[-1])\n",
    "        actual = argmax(fizz_buzz_encode(n))\n",
    "        labels = [str(n), 'fizz', 'buzz', 'fizzbuzz']\n",
    "        print(n, labels[predicted], labels[actual])\n",
    "\n",
    "        if predicted == actual:\n",
    "            num_correct += 1\n",
    "\n",
    "    print(num_correct, '/', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
